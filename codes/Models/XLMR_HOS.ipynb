{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"r8Hrl-SsHpn_"},"outputs":[],"source":["# General Libraries\n","#! pip install pandas numpy keras nltk spacy tensorflow torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"lZU4Y_OOHpoC"},"outputs":[],"source":["#! pip install scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27127,"status":"ok","timestamp":1723770327471,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"faNiqqgaIcjL","outputId":"4886db83-8aed-4b25-adc8-a0a237c2a8e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLEA4KDXOnfM"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","import numpy as np\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3YIeVxjOnfY"},"outputs":[],"source":["import tensorflow as tf\n","\n","tf.keras.backend.clear_session()\n","\n","# clear gpu memory using torch\n","import torch\n","torch.cuda.empty_cache()\n","\n","# clear output\n","from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1723770478629,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"mNogR5VmOnfb","outputId":"d9614c34-5f03-4153-9573-5b5203f6ad9b"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4KEsYU9Onff"},"outputs":[],"source":["train_path = (\"/content/drive/MyDrive/ViHOS/data/Sequence_labeling_based_version/Word/dev_BIO_Word.csv\")\n","dev_path = (\"/content/drive/MyDrive/ViHOS/data/Sequence_labeling_based_version/Word/test_BIO_Word.csv\")\n","test_path = (\"/content/drive/MyDrive/ViHOS/data/Sequence_labeling_based_version/Word/train_BIO_Word.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kxoa7w9yOnfg"},"outputs":[],"source":["from transformers import (\n","    AutoModel, AutoConfig, XLMRobertaModel,\n","    AutoTokenizer, AutoModelForSequenceClassification\n",")\n","\n","input_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","input_model.resize_token_embeddings(len(tokenizer))\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"g3iJR318Onfi"},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgXlU_4zOnfm"},"outputs":[],"source":["import pandas as pd\n","import transformers\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","\n","#clear output\n","from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKV2F-EoOnfn"},"outputs":[],"source":["def prepare_data(file_path):\n","    df = pd.read_csv(file_path)\n","\n","    # remove nan\n","    df = df.dropna()\n","    df = df.reset_index(drop=True)\n","\n","    texts = df['Word'].tolist()\n","    spans = df['Tag'].tolist()\n","\n","    # convert spans to binary representation\n","    binary_spans = []\n","    for span in spans:\n","        binary_span = []\n","        span = span.split(' ')\n","        for s in span:\n","            if s == 'O':\n","                binary_span.append(0)\n","            else:\n","                binary_span.append(1)\n","        binary_spans.append(binary_span)\n","\n","    return texts, binary_spans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9iHsbPjOnfp"},"outputs":[],"source":["# Dataloader function\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, texts, spans, tokenizer, max_len):\n","        self.texts = texts\n","        self.spans = spans\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        span = self.spans[idx]\n","\n","        # Tokenize and prepare the input data\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n","\n","        # Convert tensors to appropriate shape\n","        input_ids = encoding['input_ids'].squeeze(0)\n","        attention_mask = encoding['attention_mask'].squeeze(0)\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'spans': torch.tensor(span)  # Ensure spans is converted to tensor\n","        }\n","\n","# class TextDataset(torch.utils.data.Dataset):\n","#     def __init__(self, texts, spans, tokenizer, max_len):\n","#         self.texts = [tokenizer(text,\n","#                                 padding='max_length',\n","#                                 max_length = 64, truncation=True,\n","#                                 return_tensors=\"pt\")for text in texts]\n","#         self.spans = []\n","\n","#         for span in spans:\n","#             if len(span) < max_len:\n","#                 self.spans.append(span + [0] * (max_len - len(span)))\n","#             else:\n","#                 self.spans.append(span[:max_len])\n","\n","#         self.spans = torch.tensor(self.spans)\n","\n","#     def __len__(self):\n","#         return len(self.spans)\n","\n","#     def __getitem__(self, index):\n","#         return self.texts[index], self.spans[index]\n","\n","def create_dataloader(texts, spans, batch_size, tokenizer, max_len, shuffle=True):\n","    dataset = TextDataset(texts, spans, tokenizer, max_len)\n","    # return texts\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","    print(dataloader)\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U861u-MLHpoK"},"outputs":[],"source":["# import os\n","# cwd = os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEHEo-ngHpoK"},"outputs":[],"source":["# train_dir_text = str(os.path.join(cwd,train_path).replace('/codes/Models',''))\n","# dev_dir_text = str(os.path.join(cwd,dev_path).replace('/codes/Models',''))\n","# test_dir_text = str(os.path.join(cwd,test_path).replace('/codes/Models',''))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1768,"status":"ok","timestamp":1723771144116,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"w-Qyw31bOnfr","outputId":"3d0e171c-1790-4ef0-f81b-88a58436ebbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["<torch.utils.data.dataloader.DataLoader object at 0x7a6d888e7e80>\n","<torch.utils.data.dataloader.DataLoader object at 0x7a6d887aef50>\n","<torch.utils.data.dataloader.DataLoader object at 0x7a6d848fa0b0>\n"]}],"source":["batch_size = 32\n","train_dataloader = create_dataloader(*prepare_data(train_path), batch_size=batch_size, tokenizer = tokenizer, max_len=64)\n","dev_dataloader = create_dataloader(*prepare_data(dev_path), batch_size=batch_size, tokenizer = tokenizer, max_len=64, shuffle=False)\n","test_dataloader = create_dataloader(*prepare_data(test_path), batch_size=batch_size, tokenizer = tokenizer, max_len=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1723744203191,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"Lv69ozDqJjxS","outputId":"0444644a-2db9-4b1c-e1c9-4c2689e656d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[    0,  3711,     2,  ...,     1,     1,     1],\n","        [    0,  4194,   454,  ...,     1,     1,     1],\n","        [    0, 44433,     2,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 47364,    19,  ...,     1,     1,     1],\n","        [    0,  2579,     2,  ...,     1,     1,     1],\n","        [    0,   550,     2,  ...,     1,     1,     1]])\n"]}],"source":["for b in train_dataloader:\n","    print(b['input_ids'])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"gir9BmSBOnfs"},"source":["# Create Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qk9KM_GOnft"},"outputs":[],"source":["def calculate_f1(preds, y):\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    return f1_score(y.cpu(), max_preds.cpu(), average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNxX9SOsOnfu"},"outputs":[],"source":["class MultiTaskModel(nn.Module):\n","    def __init__(self, input_model):\n","        super(MultiTaskModel, self).__init__()\n","        self.bert = input_model\n","        self.span_classifier = nn.Linear(768, 1)  # Chuyển từ kích thước đầu ra của BERT (768) thành 1\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n","        last_hidden_state = output[0]\n","        last_hidden_state = self.dropout(last_hidden_state)\n","        span_logits = self.span_classifier(last_hidden_state)\n","\n","        span_logits = span_logits.mean(dim=1)  # Tính trung bình theo chiều 1 để giảm kích thước thành [batch_size, 1]\n","        span_logits = span_logits.unsqueeze(-1)  # Thêm chiều cuối cùng để có kích thước [batch_size, 1, 1]\n","        span_logits = torch.sigmoid(span_logits)\n","\n","        return span_logits\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcYtSjDAOnfv"},"outputs":[],"source":["# Training function with gradient accumulation\n","def train(model, train_dataloader, dev_dataloader, criterion_span, optimizer_spans, device, num_epochs, accumulation_steps):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        print(f'Epoch: {epoch+1}/{num_epochs}')\n","        for i, batch in enumerate(tqdm(train_dataloader)):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            spans = batch['spans'].float().to(device)\n","\n","            # Forward pass\n","            span_logits = model(input_ids, attention_mask)\n","            loss = criterion_span(span_logits.squeeze(), spans.squeeze()) / accumulation_steps\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            if (i + 1) % accumulation_steps == 0:\n","                optimizer_spans.step()\n","                optimizer_spans.zero_grad()\n","\n","            total_loss += loss.item() * accumulation_steps\n","\n","        # Handle the last accumulation step if not perfectly divisible\n","        if (i + 1) % accumulation_steps != 0:\n","            optimizer_spans.step()\n","            optimizer_spans.zero_grad()\n","\n","        # Calculate validation loss and F1-score\n","        val_loss = 0\n","        span_preds = []\n","        span_targets = []\n","\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in tqdm(dev_dataloader):\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                spans = batch['spans'].float().to(device)\n","                span_logits = model(input_ids, attention_mask)\n","                loss_span = criterion_span(span_logits.squeeze(), spans.squeeze())\n","                val_loss += loss_span.item()\n","\n","                # Collect predictions and targets for F1 score\n","                span_preds.append(span_logits.squeeze().cpu().numpy().flatten())\n","                span_targets.append(spans.cpu().numpy().flatten())\n","\n","        # Flatten lists of predictions and targets\n","        span_preds = np.concatenate(span_preds)\n","        span_targets = np.concatenate(span_targets)\n","        span_preds = (span_preds > 0.5).astype(int)\n","        span_f1 = f1_score(span_targets, span_preds, average='macro')\n","\n","        print(f'Training loss: {total_loss / len(train_dataloader)}')\n","        print(f'Validation loss: {val_loss / len(dev_dataloader)}')\n","        print(f'Span F1-score: {span_f1}')\n","\n","\n","\n","# def train(model, train_dataloader, dev_dataloader, criterion_span, optimizer_spans, device, num_epochs):\n","#     model.train()\n","#     for epoch in range(num_epochs):\n","#         total_loss = 0\n","#         print('Epoch: ', epoch+1)\n","#         for texts, spans in tqdm(train_dataloader):\n","#             input_ids = texts['input_ids'].squeeze(1).to(device)\n","#             attention_mask = texts['attention_mask'].to(device)\n","#             spans = spans.float().to(device)\n","\n","#             optimizer_spans.zero_grad()\n","#             span_logits = model(input_ids, attention_mask)\n","#             loss_span = criterion_span(span_logits.squeeze(), spans)\n","\n","#             loss = loss_span\n","#             loss.backward()\n","\n","#             optimizer_spans.step()\n","#             total_loss += loss.item()\n","\n","#         # Calculate validation loss and macro F1-score\n","#         val_loss = 0\n","#         span_preds = []\n","#         span_targets = []\n","\n","#         for texts, spans in tqdm(dev_dataloader):\n","#             input_ids = texts['input_ids'].squeeze(1).to(device)\n","#             attention_mask = texts['attention_mask'].to(device)\n","#             spans = spans.float().to(device)\n","#             with torch.no_grad():\n","#                 span_logits = model(input_ids, attention_mask)\n","#                 loss_span = criterion_span(span_logits.squeeze(), spans)\n","\n","#                 val_loss += loss_span #+ loss_label\n","\n","#             # Save the true labels and predicted labels for each sample\n","#             span_preds.append(span_logits.squeeze().cpu().numpy().flatten())\n","#             span_targets.append(spans.cpu().numpy().flatten())\n","\n","#         span_preds = np.concatenate(span_preds)\n","#         span_targets = np.concatenate(span_targets)\n","#         span_preds = (span_preds > 0.5).astype(int)\n","#         span_f1 = f1_score(span_targets, span_preds, average='macro')\n","\n","#         print('Training loss: ', total_loss/len(train_dataloader))\n","#         print('Validation loss: ', val_loss/len(dev_dataloader))\n","#         print('Span F1-score: ', span_f1)\n"]},{"cell_type":"markdown","metadata":{"id":"eRB9WDRMOnfw"},"source":["# Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"besag50DOnfx","outputId":"7e3e7ea3-07b1-4d4a-bea5-c71980ca6d23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:41<00:00,  2.70it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.49886026400901856\n","Validation loss: 0.42146154854978835\n","Span F1-score: 0.45313072880596406\n","Epoch: 2/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.40457544468958445\n","Validation loss: 0.3650069402619487\n","Span F1-score: 0.45313072880596406\n","Epoch: 3/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.35451893880963326\n","Validation loss: 0.339992056006477\n","Span F1-score: 0.6858525531777235\n","Epoch: 4/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.3173425789888299\n","Validation loss: 0.3266323388775899\n","Span F1-score: 0.7484248240729137\n","Epoch: 5/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.27823310350537844\n","Validation loss: 0.32553797302146753\n","Span F1-score: 0.7489516485099821\n","Epoch: 6/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.2517178525481749\n","Validation loss: 0.35497870514435426\n","Span F1-score: 0.7498911695323272\n","Epoch: 7/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.23104148303423452\n","Validation loss: 0.33992839748305936\n","Span F1-score: 0.7534703940847907\n","Epoch: 8/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.21478049882576553\n","Validation loss: 0.3667199858774742\n","Span F1-score: 0.7578034393839364\n","Epoch: 9/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.20332127471172481\n","Validation loss: 0.37268892096444256\n","Span F1-score: 0.7625362932748925\n","Epoch: 10/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1975943792030352\n","Validation loss: 0.4057709395530678\n","Span F1-score: 0.7582022253376479\n","Epoch: 11/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1929516184288974\n","Validation loss: 0.37563966714910096\n","Span F1-score: 0.7539688784532739\n","Epoch: 12/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.18627558853648124\n","Validation loss: 0.4086452567062917\n","Span F1-score: 0.7613452402388912\n","Epoch: 13/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.18360065899515918\n","Validation loss: 0.40519845156619944\n","Span F1-score: 0.7595399437772142\n","Epoch: 14/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1798122635435894\n","Validation loss: 0.41917396962110487\n","Span F1-score: 0.7578636250197296\n","Epoch: 15/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1770416672315893\n","Validation loss: 0.4545219454249101\n","Span F1-score: 0.7599712509546356\n","Epoch: 16/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1770011853221633\n","Validation loss: 0.4317412876302288\n","Span F1-score: 0.7595072551918929\n","Epoch: 17/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1763733862130262\n","Validation loss: 0.438738785675239\n","Span F1-score: 0.7612711120811462\n","Epoch: 18/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17428985781916376\n","Validation loss: 0.4624053645745984\n","Span F1-score: 0.7574717769712149\n","Epoch: 19/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17359871213931008\n","Validation loss: 0.4691816866043068\n","Span F1-score: 0.7583784986060624\n","Epoch: 20/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17147702410594995\n","Validation loss: 0.48803345907390827\n","Span F1-score: 0.7620477082033147\n","Epoch: 21/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17521964248116\n","Validation loss: 0.4889148705683294\n","Span F1-score: 0.7585558517319\n","Epoch: 22/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17415455164422\n","Validation loss: 0.4331118837353729\n","Span F1-score: 0.7550700597380295\n","Epoch: 23/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1737623666327686\n","Validation loss: 0.47601125219038554\n","Span F1-score: 0.7612648988852719\n","Epoch: 24/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1737760501409616\n","Validation loss: 0.45227204872561355\n","Span F1-score: 0.7625343329097924\n","Epoch: 25/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16910900207612356\n","Validation loss: 0.5104074934231383\n","Span F1-score: 0.7575403175480802\n","Epoch: 26/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16941526219453834\n","Validation loss: 0.47034455497882194\n","Span F1-score: 0.7633172842638045\n","Epoch: 27/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16765326519129337\n","Validation loss: 0.5089757519641093\n","Span F1-score: 0.7601435960339364\n","Epoch: 28/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1659241335321252\n","Validation loss: 0.5258283574666296\n","Span F1-score: 0.7620340808272729\n","Epoch: 29/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16676855252184178\n","Validation loss: 0.50361610556997\n","Span F1-score: 0.7629484734139476\n","Epoch: 30/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16583681737559788\n","Validation loss: 0.5195321539150817\n","Span F1-score: 0.7618512773639146\n","Epoch: 31/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16528536978288802\n","Validation loss: 0.506963334259178\n","Span F1-score: 0.7642134630154285\n","Epoch: 32/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1648246278610388\n","Validation loss: 0.5570344380901329\n","Span F1-score: 0.7602204452389059\n","Epoch: 33/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16494091429722008\n","Validation loss: 0.529118036132838\n","Span F1-score: 0.7632152874428038\n","Epoch: 34/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16432633517532175\n","Validation loss: 0.5384750751689786\n","Span F1-score: 0.7639966564007243\n","Epoch: 35/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1706495169216955\n","Validation loss: 0.5034693677909672\n","Span F1-score: 0.7637474031748916\n","Epoch: 36/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1737223178481495\n","Validation loss: 0.4670281908075724\n","Span F1-score: 0.7563291154219492\n","Epoch: 37/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:27<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.17977792958071062\n","Validation loss: 0.42471808350334567\n","Span F1-score: 0.7624261088834691\n","Epoch: 38/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16989785228608126\n","Validation loss: 0.49220925510994024\n","Span F1-score: 0.7619372819033227\n","Epoch: 39/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16629433309778982\n","Validation loss: 0.5317576361997497\n","Span F1-score: 0.7641557923672755\n","Epoch: 40/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16407134779942556\n","Validation loss: 0.5291818395390042\n","Span F1-score: 0.7619491696027687\n","Epoch: 41/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16368929112603495\n","Validation loss: 0.5499034897202537\n","Span F1-score: 0.7629296218487396\n","Epoch: 42/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.95it/s]\n","100%|██████████| 420/420 [00:46<00:00,  9.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.16291314753951555\n","Validation loss: 0.5166276289416211\n","Span F1-score: 0.76654363610631\n","Epoch: 43/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 436/436 [02:28<00:00,  2.94it/s]\n"," 69%|██████▉   | 291/420 [00:32<00:14,  9.02it/s]"]}],"source":["# import optim\n","import torch.optim as optim\n","\n","# Set the number of epochs and the device to use for training\n","num_epochs = 100\n","accumulation_steps = 4\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","# Create an instance of the multi-task model\n","model = MultiTaskModel(input_model = input_model)\n","model.to(device)\n","\n","criterion_span = nn.BCELoss()\n","\n","# Define the optimizer\n","optimizer_spans = optim.Adam(list(model.parameters()), lr=5e-6, weight_decay=1e-5)\n","\n","train(model = model, train_dataloader = train_dataloader, dev_dataloader = dev_dataloader ,\n","      criterion_span = criterion_span, optimizer_spans = optimizer_spans ,device = device, num_epochs = num_epochs,\n","      accumulation_steps=accumulation_steps)"]},{"cell_type":"markdown","metadata":{"id":"p57pKpsSOnfx"},"source":["# Load and test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o19ogwVuOnfy"},"outputs":[],"source":["# def test(model, test_dataloader, device):\n","#     model.eval()\n","#     span_preds = []\n","#     span_targets = []\n","#     for texts, spans in tqdm(test_dataloader):\n","#         input_ids = texts['input_ids'].squeeze(1).to(device)\n","#         attention_mask = texts['attention_mask'].to(device)\n","#         spans = spans.float().to(device)\n","#         with torch.no_grad():\n","#             span_logits = model(input_ids, attention_mask)\n","\n","#         span_preds.append(span_logits.squeeze().cpu().numpy().flatten())\n","#         span_targets.append(spans.cpu().numpy().flatten())\n","\n","#     span_preds = np.concatenate(span_preds)\n","#     span_targets = np.concatenate(span_targets)\n","#     span_preds = (span_preds > 0.5).astype(int)\n","#     span_f1 = f1_score(span_targets, span_preds, average='macro')\n","\n","#     print(\"Span F1 Score: {:.4f}\".format(span_f1))\n","\n","def test(model, test_dataloader, device):\n","    model.eval()\n","    span_preds = []\n","    span_targets = []\n","\n","    for batch in tqdm(test_dataloader):\n","        # Print keys to understand the structure of batch\n","        print(\"Batch keys:\", batch.keys())\n","\n","        # Adjust the keys based on what you find\n","        # For example, if the keys are 'input_ids' and 'labels', update as follows:\n","        texts = batch['input_ids']  # Adjust this key according to your dataset\n","        spans = batch['labels']  # Adjust this key according to your dataset\n","\n","        input_ids = texts.squeeze(1).to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        spans = spans.float().to(device)\n","\n","        with torch.no_grad():\n","            span_logits = model(input_ids, attention_mask)\n","\n","        span_preds.append(span_logits.squeeze().cpu().numpy().flatten())\n","        span_targets.append(spans.cpu().numpy().flatten())\n","\n","    span_preds = np.concatenate(span_preds)\n","    span_targets = np.concatenate(span_targets)\n","    span_preds = (span_preds > 0.5).astype(int)\n","    span_f1 = f1_score(span_targets, span_preds, average='macro')\n","\n","    print(\"Span F1 Score: {:.4f}\".format(span_f1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mw9EeWhyRepl"},"outputs":[],"source":["# Save the model\n","model_path = \"/content/drive/MyDrive/ViHOS/data/ViHos_50epoch.pth\"\n","torch.save(model.state_dict(), model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7972,"status":"ok","timestamp":1723770757120,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"oQ-H4toYRxbL","outputId":"6f53e3c5-6934-480f-c9eb-5d16407f7118"},"outputs":[{"data":{"text/plain":["MultiTaskModel(\n","  (bert): XLMRobertaModel(\n","    (embeddings): XLMRobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): XLMRobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): XLMRobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (span_classifier): Linear(in_features=768, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Load the model\n","device = torch.device(\"cpu\")\n","\n","model = MultiTaskModel(input_model=input_model)  # Reinitialize your model architecture\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/ViHOS/data/ViHos.pth\", map_location=torch.device('cpu')))\n","model.to(device)  # Move the model to the appropriate device (GPU or CPU)\n","model.eval()  # Set the model to evaluation mode\n"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":533,"status":"ok","timestamp":1723777683304,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"Ob053kQR0EpL"},"outputs":[],"source":["from sklearn.metrics import f1_score, recall_score, accuracy_score\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","\n","def test(model, test_dataloader, device):\n","    model.eval()  # Set the model to evaluation mode\n","    span_preds = []\n","    span_targets = []\n","\n","    for batch in tqdm(test_dataloader):\n","        # Extract components from the batch\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        spans = batch['spans'].float().to(device)  # Ensure spans are in float for loss computation\n","\n","        with torch.no_grad():  # Disable gradient computation for inference\n","            span_logits = model(input_ids, attention_mask)  # Get model predictions\n","\n","        # Append predictions and targets for later evaluation\n","        span_preds.append(span_logits.squeeze().cpu().numpy().flatten())\n","        span_targets.append(spans.cpu().numpy().flatten())\n","\n","    # Concatenate all predictions and targets\n","    span_preds = np.concatenate(span_preds)\n","    span_targets = np.concatenate(span_targets)\n","\n","    # Binarize predictions based on threshold\n","    span_preds = (span_preds > 0.5).astype(int)\n","\n","    # Calculate metrics\n","    span_f1 = f1_score(span_targets, span_preds, average='macro')\n","    span_recall = recall_score(span_targets, span_preds, average='macro')\n","    span_accuracy = accuracy_score(span_targets, span_preds)\n","\n","    print(\"Span F1 Score: {:.4f}\".format(span_f1))\n","    print(\"Span Recall: {:.4f}\".format(span_recall))\n","    print(\"Span Accuracy: {:.4f}\".format(span_accuracy))\n"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":902,"status":"ok","timestamp":1723777686776,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"0yWUrqxr4936","outputId":"059fa7b0-6ccb-42f4-91a7-5cebdb563645"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["def create_subset(dataloader, subset_size=100):\n","    subset_texts = []\n","    subset_spans = []\n","\n","    for i, batch in enumerate(dataloader):\n","        if i * dataloader.batch_size >= subset_size:\n","            break\n","\n","        # Extract data based on batch structure\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        spans = batch['spans']\n","\n","        subset_texts.append({\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask\n","        })\n","        subset_spans.append(spans)\n","\n","    # Convert lists to tensors if needed\n","    subset_texts = {\n","        'input_ids': torch.cat([x['input_ids'] for x in subset_texts], dim=0),\n","        'attention_mask': torch.cat([x['attention_mask'] for x in subset_texts], dim=0)\n","    }\n","    subset_spans = torch.cat(subset_spans, dim=0)\n","\n","    return subset_texts, subset_spans\n","\n","# Create a subset dataloader\n","def create_subset_dataloader(dataloader, subset_size=1000):\n","    subset_texts, subset_spans = create_subset(dataloader, subset_size)\n","\n","    # Define a new dataset and dataloader\n","    class SubsetDataset(torch.utils.data.Dataset):\n","        def __init__(self, texts, spans):\n","            self.texts = texts\n","            self.spans = spans\n","\n","        def __len__(self):\n","            return len(self.spans)\n","\n","        def __getitem__(self, idx):\n","            return {\n","                'input_ids': self.texts['input_ids'][idx],\n","                'attention_mask': self.texts['attention_mask'][idx],\n","                'spans': self.spans[idx]\n","            }\n","\n","    subset_dataset = SubsetDataset(subset_texts, subset_spans)\n","    subset_dataloader = torch.utils.data.DataLoader(\n","        subset_dataset, batch_size=dataloader.batch_size, shuffle=False, num_workers=4\n","    )\n","    return subset_dataloader\n","\n","# Assuming test_dataloader is defined\n","subset_dataloader = create_subset_dataloader(test_dataloader, subset_size=1000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucqIMCKKRzsy","outputId":"2e5949e8-3226-488d-f5f4-4d0b2fe096b0"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 16%|█▌        | 5/32 [00:47<03:42,  8.23s/it]"]}],"source":["# Example of using the model for inference\n","test(model, subset_dataloader, device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1723777464456,"user":{"displayName":"shpr lk","userId":"10059327734999523374"},"user_tz":-420},"id":"-UitYax3wEsT","outputId":"4ba36f8a-bf23-4869-b100-e1bdd6eedbc9"},"outputs":[],"source":["# Example input sentence\n","sentence = \"<điền đoạn text để sử dụng thử model>\"\n","\n","# Step 1: Tokenize the input sentence\n","encoding = tokenizer(sentence, truncation=True, padding='max_length', max_length=64, return_tensors='pt')\n","\n","# Step 2: Prepare input tensors\n","input_ids = encoding['input_ids'].to(device)\n","attention_mask = encoding['attention_mask'].to(device)\n","\n","# Step 3: Pass the tensors through the model\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","    output = model(input_ids, attention_mask)\n","\n","# Step 4: Interpret the output\n","# Assuming the model predicts binary spans (0 or 1)\n","span_logits = output.squeeze().cpu().numpy()\n","span_predictions = (span_logits > 0.5).astype(int)  # Convert probabilities to binary predictions\n","\n","# Print the results\n","print(\"Input Sentence:\", sentence)\n","print(\"Predicted Spans:\", span_predictions)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"2ea4058ebff17680e9aef3310abdc85a026daf30b518fcd609e9534b2c19ba1f"}}},"nbformat":4,"nbformat_minor":0}
